{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d8a273",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain.chains'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_chroma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Chroma\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatPromptTemplate\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_retrieval_chain\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcombine_documents\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_stuff_documents_chain\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 1. Setup & Configuration\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# ðŸ›‘ PASTE YOUR TOKEN BELOW (Keep the quotes \"\")\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain.chains'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFaceEndpoint\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# ==========================================\n",
    "# 1. Setup & Configuration\n",
    "# ==========================================\n",
    "# ðŸ›‘ PASTE YOUR TOKEN BELOW (Keep the quotes \"\")\n",
    "HF_TOKEN = \"PASTE_YOUR_HF_TOKEN_HERE\" \n",
    "\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "VECTOR_DB_PATH = '../vector_store'\n",
    "\n",
    "# ==========================================\n",
    "# 2. Load the Vector Database\n",
    "# ==========================================\n",
    "print(\"Loading Vector Store...\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    persist_directory=VECTOR_DB_PATH,\n",
    "    embedding_function=embedding_model\n",
    ")\n",
    "\n",
    "# Create the Retriever (The tool that searches for files)\n",
    "# k=5 means \"Find the top 5 most relevant complaints\"\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# Test the Retriever quickly\n",
    "print(\"\\nTesting retrieval for 'hidden fees'...\")\n",
    "docs = retriever.invoke(\"hidden fees\")\n",
    "print(f\"Found {len(docs)} relevant documents.\")\n",
    "print(f\"Sample snippet: {docs[0].page_content[:100]}...\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. Initialize the LLM (The \"Mouth\")\n",
    "# ==========================================\n",
    "print(\"\\nConnecting to Mistral-7B via Hugging Face...\")\n",
    "\n",
    "# We use Mistral-7B-Instruct. It's fast, smart, and free via API.\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    do_sample=False,\n",
    "    temperature=0.1,  # Low temperature = more factual, less creative\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 4. Define the Prompt Template\n",
    "# ==========================================\n",
    "# This tells the AI how to behave.\n",
    "system_prompt = (\n",
    "    \"You are a senior financial analyst at CrediTrust. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, say that you don't know. \"\n",
    "    \"Keep the answer concise and professional.\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 5. Build the RAG Chain\n",
    "# ==========================================\n",
    "# This glues everything together: Retriever -> Prompt -> LLM\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# ==========================================\n",
    "# 6. Evaluation Loop\n",
    "# ==========================================\n",
    "print(\"\\nRunning Evaluation Questions...\")\n",
    "\n",
    "test_questions = [\n",
    "    \"What are the main complaints regarding Credit Cards?\",\n",
    "    \"Why are customers upset about Personal Loans?\",\n",
    "    \"Have there been issues with money transfers?\",\n",
    "    \"What kind of fraud is being reported?\",\n",
    "    \"Are there any billing disputes mentioned?\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for q in test_questions:\n",
    "    print(f\"\\nAsking: {q}\")\n",
    "    # Run the chain\n",
    "    response = rag_chain.invoke({\"input\": q})\n",
    "    \n",
    "    # Store result\n",
    "    answer = response[\"answer\"]\n",
    "    \n",
    "    # Get the sources (evidence) used\n",
    "    sources = [doc.metadata['product'] for doc in response[\"context\"]]\n",
    "    \n",
    "    results.append({\n",
    "        \"Question\": q,\n",
    "        \"Answer\": answer,\n",
    "        \"Sources\": list(set(sources)) # Unique sources\n",
    "    })\n",
    "    \n",
    "    print(f\"Answer: {answer.strip()}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# ==========================================\n",
    "# 7. Save Results\n",
    "# ==========================================\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"../data/processed/rag_evaluation_results.csv\", index=False)\n",
    "print(\"\\nEvaluation complete! Results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c179a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Maireg\\Documents\\GitHub\\creditrust-complaint-rag\\.venv\\Scripts\\python.exe\n",
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
